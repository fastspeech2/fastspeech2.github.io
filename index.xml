<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FastSpeech2</title>
    <link>https://fastspeech2.github.io/</link>
    <description>Recent content on FastSpeech2</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 20 May 2020 15:30:00 +0901</lastBuildDate>
    
	<atom:link href="https://fastspeech2.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech</title>
      <link>https://fastspeech2.github.io/fastspeech2/</link>
      <pubDate>Wed, 20 May 2020 15:30:00 +0901</pubDate>
      
      <guid>https://fastspeech2.github.io/fastspeech2/</guid>
      <description>ArXiv: arXiv:2006.04558
Reddit Discussions: Click me
Authors  Yi Ren* (Zhejiang University) rayeren@zju.edu.cn Chenxu Hu* (Zhejiang University) chenxuhu@zju.edu.cn Xu Tan (Microsoft Research) xuta@microsoft.com Tao Qin (Microsoft Research) taoqin@microsoft.com Sheng Zhao (Microsoft Azure Speech) Sheng.Zhao@microsoft.com Zhou Zhao (Zhejiang University) zhaozhou@zju.edu.cn Tie-Yan Liu (Microsoft Research) tyliu@microsoft.com  * Equal contribution.
Abstract Advanced text-to-speech (TTS) models such as FastSpeech~\cite{ren2019fastspeech} can synthesize speech significantly faster than previous autoregressive models with comparable quality. The training of FastSpeech model relies on an autoregressive teacher model for duration prediction (to provide more information as input) and knowledge distillation (to simplify the data distribution in output), which can ease the one-to-many mapping problem (i.</description>
    </item>
    
  </channel>
</rss>